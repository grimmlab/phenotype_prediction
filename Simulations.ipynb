{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb64203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f24bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_informative(X, snp_ids, X_raw=None):\n",
    "    tmp = X == X[0, :]\n",
    "    a = (~tmp.all(0)).nonzero()[0]\n",
    "    X = X[:, a]\n",
    "    snp_ids = snp_ids[a]\n",
    "    if X_raw is not None:\n",
    "        X_raw = X_raw[:, a]\n",
    "        return X, X_raw, snp_ids\n",
    "    else:\n",
    "        return X, snp_ids\n",
    "    \n",
    "def filter_duplicates(X, snp_ids, X_raw=None):\n",
    "    uniques, index = np.unique(X, return_index=True, axis=1)\n",
    "    X = uniques[:, np.argsort(index)]\n",
    "    snp_ids = snp_ids[np.sort(index)]\n",
    "    if X_raw is not None:\n",
    "        X_raw = X_raw[:,np.sort(index)]\n",
    "        return X, X_raw, snp_ids\n",
    "    else:\n",
    "        return X, snp_ids\n",
    "    \n",
    "def filter_maf(X, snp_ids, threshold, X_raw=None):\n",
    "    freq = (np.sum(X, 0)) / (2 * X.shape[0])\n",
    "    tmp = np.where(freq <= threshold)[0]\n",
    "    X = np.delete(X, tmp, axis=1)\n",
    "    snp_ids = np.delete(snp_ids, tmp, axis=0)\n",
    "    if X_raw is not None:\n",
    "        X_raw = np.delete(X_raw, tmp, axis=1)\n",
    "        return X, X_raw, snp_ids\n",
    "    else:\n",
    "        return X, snp_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aaca3f",
   "metadata": {},
   "source": [
    "# load genotype matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c11787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2029, 10000)\n",
      "(10000,)\n",
      "(2029,)\n"
     ]
    }
   ],
   "source": [
    "file_name=\"../data/ld_pruned_arabidopsis_10k_maf10.h5\"\n",
    "with h5py.File(file_name, \"r\") as f:\n",
    "    sample_ids = f['sample_ids'][:].astype(str)\n",
    "    X = f['X_012'][:]\n",
    "    snp_ids = f['snp_ids'][:].astype(str)\n",
    "\n",
    "print(X.shape)\n",
    "print(snp_ids.shape)\n",
    "print(sample_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5090cb7",
   "metadata": {},
   "source": [
    "# compute simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e388b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simulation(X, sample_ids, snp_ids, number_of_samples, number_of_snps, explained_variance, maf, heritability, \n",
    "                   seed, number_background_snps, distribution, shape, effect):\n",
    "\n",
    "    # sanity checks\n",
    "    if effect=='add' and len(explained_variance) != number_of_snps:\n",
    "        raise Exception('Need explained variance for each causative SNP!')\n",
    "        \n",
    "    # get random samples for X\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    samples_to_take = random.sample(list(enumerate(sample_ids)), number_of_samples)\n",
    "    sample_indices = np.array(samples_to_take)[:,0].astype(int)\n",
    "    sample_ids_sampled = np.array(samples_to_take)[:,1]\n",
    "    X_sampled = X[sample_indices,:]\n",
    "    print('X after selection of samples ', X_sampled.shape)\n",
    "    \n",
    "    #filter non-informative\n",
    "    X_sampled, snp_ids_sampled = filter_non_informative(X_sampled, snp_ids, X_raw=None)\n",
    "    print('X after non-informative filter ', X_sampled.shape)\n",
    "    \n",
    "    # filter for duplicates\n",
    "    X_sampled, snp_ids_sampled = filter_duplicates(X_sampled, snp_ids_sampled,  X_raw=None)\n",
    "    print('X after duplicate filter ', X_sampled.shape)\n",
    "    \n",
    "    # filter for MAF\n",
    "    X_sampled, snp_ids_sampled = filter_maf(X_sampled, snp_ids_sampled, maf, X_raw=None)\n",
    "    print('X after maf filter ', X_sampled.shape)\n",
    "    \n",
    "    # compute simulations\n",
    "    # choose random causal SNPs\n",
    "    causal_snps = random.sample(list(enumerate(snp_ids_sampled)), number_of_snps)\n",
    "    causal_snps_indices = np.array(causal_snps)[:,0].astype(int)\n",
    "    causal_snps_ids = np.array(causal_snps)[:,1]\n",
    "\n",
    "    # choose background SNPs\n",
    "    X_non_causal = np.delete(X_sampled, causal_snps_indices, axis=1)\n",
    "    snp_ids_non_causal = np.delete(snp_ids_sampled, causal_snps_indices, axis=0)\n",
    "    background_SNPs_indices = np.random.choice(X_non_causal.shape[1], number_background_snps, replace=False)\n",
    "    background_SNPs = X_non_causal[:,background_SNPs_indices]\n",
    "    background_snp_ids = snp_ids_non_causal[background_SNPs_indices]\n",
    "\n",
    "    # compute effect size for background\n",
    "    betas_background = np.random.normal(loc=0, scale=0.1, size=number_background_snps)\n",
    "\n",
    "    # add background\n",
    "    simulated_phenotype = np.matmul(background_SNPs, betas_background)\n",
    "    \n",
    "    \n",
    "    # set heritability\n",
    "    background_variance = np.var(simulated_phenotype)\n",
    "    noise_variance = background_variance/heritability-background_variance\n",
    "    \n",
    "    # add random noise \n",
    "    if distribution=='gamma':\n",
    "        random_noise = np.random.gamma(shape=shape, scale=np.sqrt(noise_variance/shape), size=number_of_samples)\n",
    "    elif distribution=='normal':\n",
    "        random_noise = np.random.normal(loc=0, scale=np.sqrt(noise_variance), size=number_of_samples)\n",
    "    simulated_phenotype = simulated_phenotype + random_noise\n",
    "\n",
    "    #compute explained variances for more than 1 snp\n",
    "    if effect == 'add' and number_of_snps>1:\n",
    "        c = explained_variance[0]\n",
    "        explained_variance = np.random.normal(6,2,4)\n",
    "        explained_variance = np.append(explained_variance, [c-sum(explained_variance)])\n",
    "        explained_variance = explained_variance/100\n",
    "        explained_variance.sort()\n",
    "        \n",
    "    # add causative markers with effect sizes\n",
    "    caus_beta = []\n",
    "    for i in range(number_of_snps):\n",
    "        beta = np.sqrt((explained_variance[i]/(1-explained_variance[i])*\n",
    "                        (np.var(simulated_phenotype)/np.var(X_sampled[:,causal_snps_indices[i]]))))\n",
    "        simulated_phenotype += beta*X_sampled[:,causal_snps_indices[i]]\n",
    "        caus_beta.append(beta)\n",
    "    if effect == 'mult':\n",
    "        mult_snp = np.multiply(X_sampled[:,causal_snps_indices[0]], X_sampled[:,causal_snps_indices[1]])\n",
    "        beta = np.sqrt((explained_variance[-1]/(1-explained_variance[-1])*\n",
    "                                (np.var(simulated_phenotype)/np.var(mult_snp))))\n",
    "        simulated_phenotype += beta*mult_snp\n",
    "        caus_beta.append(beta)\n",
    "                \n",
    "    return simulated_phenotype, sample_ids_sampled, causal_snps_ids, background_snp_ids, betas_background, caus_beta, explained_variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7454ed",
   "metadata": {},
   "source": [
    "# some notes:\n",
    "- the function is missing some sanity checks! Make sure all your parameters make sense!\n",
    "- for each additional simulation add the corresponding parameters to the lists below. Then just run the cell below and the csv file with all the simulations will be generated\n",
    "- number_of_simulation: basically the NAME of the simulation\n",
    "- number_of_samples: amount of samples the simulated phenotype will have\n",
    "- number_of_snps: amount of causative SNPs\n",
    "- explained_variance: variance of causative SNP, if you use more than one causative SNP, then you have to specify the explained variance for each SNP separately (add them as a list)\n",
    "- shape: only relevant if distribution='gamma', shape of distribution\n",
    "- distribution: 'normal' or 'gamma' are possible\n",
    "- effect: 'add' for additive effect, 'mult' for multiplicative, \n",
    "    if 'mult' it computes: beta(ev1)$\\cdot$SNP1 + beta(ev2)$\\cdot$SNP2 + beta(ev3)$\\cdot$SNP1$\\cdot$SNP2\n",
    "- will save the simulated phenotype, the simulated phenotype shifted to remove negative values, snp_ids of background SNPs and corresponding effect sizes(betas), a config file with the causal markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35335aee",
   "metadata": {},
   "source": [
    "# set parameters for simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d06a28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "maf=0\n",
    "heritability=[0.85, 0.7, 0.95]\n",
    "number_background_snps=1000\n",
    "\n",
    "number_of_simulation=[39, 40, 41]\n",
    "number_of_samples=[1000]*3\n",
    "number_of_snps=[2]*3\n",
    "explained_variance=[[0.01, 0.01, 0.28]]*3\n",
    "shape=[None]*3\n",
    "distribution=['normal']*3\n",
    "effect=['mult']*3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826d3dc",
   "metadata": {},
   "source": [
    "# create and save all simulations specified in parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "839a113d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation  39\n",
      "X after selection of samples  (1000, 10000)\n",
      "X after non-informative filter  (1000, 10000)\n",
      "X after duplicate filter  (1000, 9978)\n",
      "X after maf filter  (1000, 9978)\n",
      "Simulation  40\n",
      "X after selection of samples  (1000, 10000)\n",
      "X after non-informative filter  (1000, 10000)\n",
      "X after duplicate filter  (1000, 9972)\n",
      "X after maf filter  (1000, 9972)\n",
      "Simulation  41\n",
      "X after selection of samples  (1000, 10000)\n",
      "X after non-informative filter  (1000, 10000)\n",
      "X after duplicate filter  (1000, 9970)\n",
      "X after maf filter  (1000, 9970)\n"
     ]
    }
   ],
   "source": [
    "causal_markers = []\n",
    "seeds = []\n",
    "background_markers = []\n",
    "background_betas = []\n",
    "causative_beta = []\n",
    "ev = []\n",
    "\n",
    "df_final = pd.DataFrame(index=sample_ids)\n",
    "\n",
    "for i in range(len(number_of_simulation)):\n",
    "    print('Simulation ', number_of_simulation[i])\n",
    "    seed = 41 + number_of_simulation[i]\n",
    "    simulated_phenotype, sample_ids_sampled, causal_snps_ids, background_snp_ids, betas_background, beta, c = get_simulation(X, \n",
    "                    sample_ids, snp_ids, number_of_samples[i], number_of_snps[i], explained_variance[i], maf, heritability[i], \n",
    "                       seed, number_background_snps, distribution[i], shape[i], effect[i])\n",
    "    \n",
    "    causal_markers.append(causal_snps_ids)\n",
    "    seeds.append(seed)\n",
    "    background_markers.append(background_snp_ids)\n",
    "    background_betas.append(betas_background)\n",
    "    causative_beta.append(beta)\n",
    "    ev.append(c)\n",
    "    \n",
    "    df_sim = pd.DataFrame({f'sim{number_of_simulation[i]}': simulated_phenotype,\n",
    "                    f'sim{number_of_simulation[i]}_shift': simulated_phenotype + np.abs(np.min(simulated_phenotype)) + 1},\n",
    "                     index=sample_ids_sampled)\n",
    "    df_final=df_final.join(df_sim)\n",
    "    \n",
    "df_final.to_csv(f'Simulation_10k_maf10_{number_of_simulation[0]}-{number_of_simulation[-1]}.csv')\n",
    "\n",
    "df_causal = pd.DataFrame({'simulation':number_of_simulation,\n",
    "                         'seed': seeds,\n",
    "                          'heritability': heritability,\n",
    "                          'samples': number_of_samples,\n",
    "                          'SNPs': number_of_snps,\n",
    "                          'explained_var': ev,\n",
    "                         'causal_marker': causal_markers,\n",
    "                         'causal_beta': causative_beta,\n",
    "                         'effect': effect,\n",
    "                         'distribution': distribution,\n",
    "                         'shape': shape})\n",
    "\n",
    "df_causal.to_csv(f'simulation_config_10k_maf10_{number_of_simulation[0]}-{number_of_simulation[-1]}.csv', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0a60e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ('sim39', 'sim40', 'sim41')\n",
    "bg = np.array(background_markers).T\n",
    "df_background = pd.DataFrame(bg, columns=col)\n",
    "df_background.to_csv(f'background_10k_maf10_{number_of_simulation[0]}-{number_of_simulation[-1]}.csv', index=None)\n",
    "bb = np.array(background_betas).T\n",
    "df_bb = pd.DataFrame(bb, columns=col)\n",
    "df_bb.to_csv(f'betas_background_10k_maf10_{number_of_simulation[0]}-{number_of_simulation[-1]}.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
