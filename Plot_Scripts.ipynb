{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import warnings\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib_venn import venn3, venn3_circles, venn3_unweighted\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 12\n",
    "# plt.rc('text.latex', preamble=r'\\usepackage{lmodern}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optim Result Plots\n",
    "The following code was used to generate the heat maps for the real-world and synthetic data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First the results for the different species were gathered and converted to a pandas DataFrame for plotting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## real world data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_results_overview = pd.read_csv('Results/Results_overview_arabidopsis_thaliana.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "sorter = ['BLUP', 'BayesB', 'LASSO', 'ElasticNet', 'SVR', 'RF', 'XGB', 'MLP', 'CNN', 'LCNN']\n",
    "label_df = pd.DataFrame(columns=sorter)\n",
    "plot_data = df_results_overview.filter(regex='mean').astype(float)\n",
    "plot_data = plot_data[[s + '_mean' for s in sorter]]\n",
    "label_info = df_results_overview.filter(regex='mean|std').astype(float)\n",
    "row_max = plot_data.idxmax(axis=1)\n",
    "for index, row in label_info.iterrows():\n",
    "    for model in label_df.columns:\n",
    "        number = \"{:.3f}\".format(row[model + '_mean']) + \"\\n\\u00B1 {:.3f}\".format(row[model + '_std'])\n",
    "        #if row_max[index] == model + '_mean':\n",
    "        #    label_df.at[index, model] = r\"$\\bf{\" + number + \"}$\"\n",
    "        #else:\n",
    "        label_df.at[index, model] = number\n",
    "        #else:\n",
    "            #label_df.at[index, model] = \"{:.3f}\".format(row[model + '_mean'])\n",
    "sns.heatmap(data=plot_data, cmap=\"Spectral\", cbar_kws={\"shrink\": .75}, vmin=-0.25, vmax=0.65,\n",
    "            annot=label_df, fmt='', linewidths=1.5, linecolor='white', cbar=True, annot_kws={\"size\": 12})    \n",
    "ax.set_xticklabels(label_df.columns, rotation=0)\n",
    "ax.set_yticklabels(df_results_overview['phenotype'], rotation=0)\n",
    "ax.tick_params(top=False,\n",
    "               bottom=False,\n",
    "               left=False,\n",
    "               right=False,\n",
    "               labelleft=True,\n",
    "               labelbottom=True)\n",
    "for row, index in enumerate(plot_data.index):\n",
    "    position = label_df.columns.get_loc(row_max[index].split('_')[0])\n",
    "    #print(position)\n",
    "    ax.add_patch(Rectangle((position, row), 1, 1, fill=False, edgecolor='0', lw=1.5))\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.savefig('heatmap_real_world_data.svg', bbox_inches='tight', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## simulation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_results_overview = pd.read_csv('Results/Results_overview_simulated_data.csv')\n",
    "sim_085 = ['sim' + str(index) + '_shift' for index in [18, 16, 15, 17, 19, 39, 21, 22, 20, 42, 45, 48]]\n",
    "sim_07 = ['sim' + str(index) + '_shift' for index in [23, 24, 25, 26, 27, 40, 29, 30, 28, 43, 46, 49]]\n",
    "sim_095 = ['sim' + str(index) + '_shift' for index in [31, 32, 33, 34, 35, 41, 37, 38, 36, 44, 47, 50]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorter = ['BLUP', 'BayesB', 'LASSO', 'ElasticNet', 'SVR', 'RF', 'XGB', 'MLP', 'CNN', 'LCNN']\n",
    "for sim_config, number in zip([sim_07, sim_085, sim_095], ['07', '085', '095']):\n",
    "    df_config = df_results_overview[df_results_overview['phenotype'].isin(sim_config)]\n",
    "    df_config = df_config.set_index('phenotype').loc[sim_config]\n",
    "    df_config.loc[:, 'phenotype'] = ['A' + ' (#100)',\n",
    "                                     'B' + ' (#500)', \n",
    "                                     'C' + ' (#1000)', \n",
    "                                     'D' + ' (#2000)',\n",
    "                                     'E' + ' (MultWeak)', \n",
    "                                     'F' + ' (MultStrong)', \n",
    "                                     'G' + ' (SkewedWeak)', \n",
    "                                     'H' + ' (SkewedStrong)',\n",
    "                                     'I' + ' (Add5)', \n",
    "                                     'J' + ' (Add20)',\n",
    "                                     'K' + ' (Add50)',\n",
    "                                     'L' + ' (Add100)'\n",
    "                                    ]\n",
    "    df_config.reset_index(inplace=True, drop=True)\n",
    "    label_df = pd.DataFrame(columns=sorter)\n",
    "    for index, row in df_config.iterrows():\n",
    "        for model in label_df.columns:\n",
    "            label_df.at[index, model] = \\\n",
    "                \"{:.3f}\".format(row[model + '_mean']) + \"\\n\\u00B1 {:.3f}\".format(row[model + '_std'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "    plot_data = df_config.filter(regex='mean').astype(float)\n",
    "    plot_data = plot_data[[s + '_mean' for s in sorter]]\n",
    "    \n",
    "    # We use ax parameter to tell seaborn which subplot to use for this plot\n",
    "    sns.heatmap(data=plot_data, cmap=\"Spectral\", cbar_kws={\"shrink\": .75}, vmin=-0.25, vmax=0.7,\n",
    "                annot=label_df, fmt='', linewidths=1.5, linecolor='white', cbar=True, annot_kws={\"size\": 12, \"ha\": \"center\"})\n",
    "    ax.set_xticklabels([model.split('_')[0] for model in plot_data.columns], rotation=0)\n",
    "    ax.set_yticklabels(df_config['phenotype'], rotation=0)\n",
    "    ax.tick_params(top=False,\n",
    "                   bottom=False,\n",
    "                   left=False,\n",
    "                   right=False,\n",
    "                   labelleft=True,\n",
    "                   labelbottom=True)\n",
    "    row_max = plot_data.idxmax(axis=1)\n",
    "    for row, index in enumerate(plot_data.index):\n",
    "        position = plot_data.columns.get_loc(row_max[index])\n",
    "        ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='0', lw=1.5))\n",
    "    h = '0.' + str(number.split('0')[1])\n",
    "    fig.suptitle('Results overview on synthetic data with '+ r'$\\mathit{h=' + h + '}$', fontsize=13)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('heatmap_sim_' + number + '.svg', bbox_inches='tight', dpi=600)\n",
    "    plt.savefig('heatmap_sim_' + number + '.pdf', bbox_inches='tight', dpi=600)\n",
    "    plt.savefig('heatmap_sim_' + number + '.jpg', bbox_inches='tight', dpi=600)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feat Importance Analyse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real-world data (feat importances vs GWAS results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate data for Venn diagrams \n",
    "data = {}\n",
    "phenotypes = ['DTF1', 'RL', 'Diameter', 'FT10']\n",
    "species = 'Ara'\n",
    "for pheno in phenotypes:\n",
    "    # load data\n",
    "    en=f'Results/A_thal_{pheno}_elasticnet_feature_importances.csv'\n",
    "    xgb=f'Results/A_thal_{pheno}_xgboost_feature_importances.csv'\n",
    "    bay=f'Results/A_thal_{pheno}_bayesB_feature_importances.csv'\n",
    "    gwas_data=f'GWAS_results/ld_pruned_gwas_results_{pheno}.csv'\n",
    "    df_lin = pd.read_csv(en)\n",
    "    df_lin=df_lin.drop(df_lin[df_lin.feat_imp ==0].index)\n",
    "    df_xgb = pd.read_csv(xgb)\n",
    "    df_xgb = df_xgb.drop(df_xgb[df_xgb.feat_imp ==0].index)\n",
    "    df_rf = pd.read_csv(bay)\n",
    "    df_rf = df_rf.drop(df_rf[df_rf.feat_imp ==0].index)\n",
    "    df_gwas = pd.read_csv(gwas_data)\n",
    "    df_gwas = df_gwas.nsmallest(1000, 'p_value')\n",
    "    snp_ids=[]\n",
    "    for i in range(len(df_gwas['CHR'])):\n",
    "        snp_ids.append(str(df_gwas['POS'][i])+\"_\"+str(df_gwas['CHR'][i]))\n",
    "    \n",
    "    # compute all intersections\n",
    "    set_lin = set(df_lin['snp_id'])\n",
    "    set_xgb = set(df_xgb['snp_id'])\n",
    "    set_rf = set(df_rf['snp_id'])\n",
    "    set_gwas100 = set(snp_ids)\n",
    "\n",
    "    int_all = set.intersection(set_lin, set_xgb, set_rf)\n",
    "    int_lin_xgb = set.intersection(set_lin, set_xgb)\n",
    "    int_lin_rf = set.intersection(set_lin, set_rf)\n",
    "    int_rf_xgb = set.intersection(set_rf, set_xgb)\n",
    "\n",
    "    top100_all = set.intersection(int_all,  set_gwas100)\n",
    "    top100_lin_xgb = set.intersection(int_lin_xgb,  set_gwas100)\n",
    "    top100_lin_rf = set.intersection(int_lin_rf,  set_gwas100)\n",
    "    top100_rf_xgb = set.intersection(int_rf_xgb,  set_gwas100)\n",
    "    top100_lin = set.intersection(set_lin, set_gwas100)\n",
    "    top100_xgb = set.intersection(set_xgb, set_gwas100)\n",
    "    top100_rf = set.intersection(set_rf, set_gwas100)\n",
    "    \n",
    "    # generate list with data in right order for Venn diagram\n",
    "    part = [0]*7\n",
    "    part_top = [0]*7\n",
    "    part[6] = len(int_all)\n",
    "    part_top[6] = len(top100_all)\n",
    "    part[5] = len(int_rf_xgb)-part[6]\n",
    "    part_top[5] = len(top100_rf_xgb)-part_top[6]\n",
    "    part[4] = len(int_lin_rf)-part[6]\n",
    "    part_top[4] = len(top100_lin_rf)-part_top[6]\n",
    "    part[3] = len(set_rf)-part[4]-part[5]-part[6]\n",
    "    part_top[3] = len(top100_rf)-part_top[4]-part_top[5]-part_top[6]\n",
    "    part[2] = len(int_lin_xgb)-part[6]\n",
    "    part_top[2] = len(top100_lin_xgb)-part_top[6]\n",
    "    part[1] = len(set_xgb)-part[2]-part[6]-part[5]\n",
    "    part_top[1] = len(top100_xgb)-part_top[2]-part_top[6]-part_top[5]\n",
    "    part[0] = len(set_lin)-part[2]-part[6]-part[4]\n",
    "    part_top[0] = len(top100_lin)-part_top[2]-part_top[6]-part_top[4]\n",
    "\n",
    "    numbers = []\n",
    "    for i in range(7):\n",
    "        numbers.append(str(part[i])+'('+str(part_top[i])+')')\n",
    "        \n",
    "    data[f'{species}_{pheno}'] = numbers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create plot\n",
    "cm=1\n",
    "titles = [\n",
    "    'DTF1',\n",
    "    'RL', \n",
    "    'Diameter', \n",
    "    'FT10'\n",
    "]\n",
    "\n",
    "names = ['Ara_DTF1', 'Ara_RL', 'Ara_Diameter', 'Ara_FT10']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i in range(len(names)):\n",
    "        ax = fig.add_subplot(1, 4, i+1)\n",
    "        v = venn3_unweighted(subsets=data[names[i]], set_labels=('ElasticNet', 'XGB', 'BayesB'), ax=ax)\n",
    "        for text in v.set_labels:\n",
    "           text.set_fontsize(12)\n",
    "        for text in v.subset_labels:\n",
    "           text.set_fontsize(12)\n",
    "        ax.set_title(titles[i], fontsize=14)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "#fig.suptitle('Feature importances compared with GWAS results', fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.savefig('Venn_diagram.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Synthetic data (feat importances vs. effect sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code can be used to analyze the feature importances in comparison with the effect sizes of all simulated scenarios. Furthermore, the code for generating the scatter plots is included."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_sim_configs = pd.read_csv('Simulations/Simulation_configs_gathered.csv')\n",
    "all_feat_imps = pd.read_csv('Results/Feature_importances_all_simulations.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(\n",
    "    columns=['sim_id', 'model', '#features_with_imp', '#detected_background_snps', '#background_snps', 'ratio_background_detected', 'ratio_background_detected_by_feat_imp',\n",
    "             '#detected_causal_snps', '#causal_snps', 'ratio_causal_detected', 'causal_snps_detected', 'featimp_rank_causal_snps'])\n",
    "for sim_id in set(all_sim_configs.sim_id):\n",
    "    config_simid = all_sim_configs[all_sim_configs.sim_id == sim_id]\n",
    "    feat_imp_simid = all_feat_imps[all_feat_imps.sim_id == sim_id]\n",
    "    for model in set(feat_imp_simid.model):\n",
    "        new_row = {}\n",
    "        new_row['sim_id'] = sim_id\n",
    "        new_row['model'] = model\n",
    "        feat_imp_model = feat_imp_simid[feat_imp_simid.model == model]\n",
    "        non_zero_featimps = feat_imp_model[feat_imp_model.feat_imp != 0.0]\n",
    "        new_row['#features_with_imp'] = non_zero_featimps.shape[0]\n",
    "        background = config_simid[config_simid.type == 'background']\n",
    "        causal = config_simid[config_simid.type=='causal']\n",
    "        new_row['#detected_background_snps'] = len(set(non_zero_featimps.snp_id).intersection(set(background.snp_id)))\n",
    "        new_row['#background_snps'] = len(set(background.snp_id))\n",
    "        new_row['ratio_background_detected_by_feat_imp'] = round(new_row['#detected_background_snps'] / new_row['#features_with_imp'], 2) if new_row['#features_with_imp'] != 0 else np.nan\n",
    "        new_row['ratio_background_detected'] = round(new_row['#detected_background_snps'] / new_row['#background_snps'], 2)\n",
    "        new_row['#detected_causal_snps'] = len(set(non_zero_featimps.snp_id).intersection(set(causal.snp_id)))\n",
    "        new_row['#causal_snps'] = len(set(causal.snp_id))\n",
    "        new_row['ratio_causal_detected'] = round(new_row['#detected_causal_snps'] / new_row['#causal_snps'], 2)\n",
    "        new_row['causal_snps_detected'] = 'Yes' if new_row['ratio_causal_detected'] == 1 else 'No'\n",
    "        featimp_sorted = non_zero_featimps.sort_values(by='feat_imp', ascending=False).reset_index(drop=True)\n",
    "        new_row['featimp_rank_causal_snps'] = list(featimp_sorted[featimp_sorted.snp_id.isin(set(causal.snp_id))].index + 1)\n",
    "        stats = stats.append(new_row, ignore_index=True)\n",
    "stats = stats.sort_values(by=['sim_id', 'model'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats\n",
    "stats.to_csv('Simulated_data_statistics_beta_vs_featimp.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sim_085 = ['sim' + str(index) for index in [18, 16, 15, 17, 19, 39, 21, 22, 20, 42, 45, 48]]\n",
    "sim_07 = ['sim' + str(index) for index in [23, 24, 25, 26, 27, 40, 29, 30, 28, 43, 46, 49]]\n",
    "sim_095 = ['sim' + str(index) for index in [31, 32, 33, 34, 35, 41, 37, 38, 36, 44, 47, 50]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm=1\n",
    "titles = [\n",
    "    'A' + ' (#100)',\n",
    "    'B' + ' (#500)', \n",
    "    'C' + ' (#1000)', \n",
    "    'D' + ' (#2000)',\n",
    "    'E' + ' (MultWeak)', \n",
    "    'F' + ' (MultStrong)', \n",
    "    'G' + ' (SkewedWeak)', \n",
    "    'H' + ' (SkewedStrong)',\n",
    "    'I' + ' (Add5)', \n",
    "    'J' + ' (Add20)',\n",
    "    'K' + ' (Add50)',\n",
    "    'L' + ' (Add100)'\n",
    "]\n",
    "\n",
    "for sim_config, number in zip([sim_07, sim_085, sim_095], ['07', '085', '095']):\n",
    "    sim_info = all_sim_configs[all_sim_configs['sim_id'].isin(sim_config)]\n",
    "    feat_info = all_feat_imps[all_feat_imps['sim_id'].isin(sim_config)]\n",
    "    \n",
    "    beta_max = sim_info[sim_info['beta']!= 0]['beta'].astype(float).abs().max()\n",
    "    feat_imp_max = feat_info[feat_info['feat_imp']!=0]['feat_imp'].astype(float).abs().max()\n",
    "    beta_min = sim_info[sim_info['beta']!= 0]['beta'].astype(float).abs().min()\n",
    "    feat_imp_min = feat_info[feat_info['feat_imp']!=0]['feat_imp'].astype(float).abs().min()\n",
    "    for models in [\n",
    "        ['xgboost', 'bayesB', 'elasticnet'],\n",
    "        ['xgboost'], ['bayesB'], ['elasticnet'], ['linearregression'], ['randomforest'], ['blup']\n",
    "        ]:\n",
    "        fig = plt.figure(figsize=(12*cm, 16*cm))\n",
    "        for plot_nr, sim_id in enumerate(sim_config):\n",
    "            ax = fig.add_subplot(4, 3, plot_nr+1)\n",
    "            sim_info_for_id = sim_info[sim_info['sim_id'] == sim_id]\n",
    "            feat_info_for_id = feat_info[feat_info['sim_id'] == sim_id]\n",
    "            for model in models: #, 'xgboost', 'linearregression']:\n",
    "                feat_info_for_model = feat_info_for_id[feat_info_for_id['model'] == model]\n",
    "                plot_info = sim_info_for_id.iloc[:, 1:].join(feat_info_for_model.iloc[:, 2:].set_index('snp_id'), on=['snp_id']).fillna(0)\n",
    "                plot_info_non_zero = plot_info[plot_info['feat_imp'] != 0]\n",
    "                corr = np.corrcoef(plot_info_non_zero['beta'].astype(float), plot_info_non_zero['feat_imp'].astype(float))[0][1]\n",
    "                plot_info_non_zero['beta'] = plot_info_non_zero['beta'].astype(float).abs()\n",
    "                plot_info_non_zero['feat_imp'] = plot_info_non_zero['feat_imp'].astype(float).abs()\n",
    "                plot_info_non_zero['feat_imp'] = (plot_info_non_zero['feat_imp']-plot_info_non_zero['feat_imp'].min()) / (plot_info_non_zero['feat_imp'].max()-plot_info_non_zero['feat_imp'].min())\n",
    "                plot_info_background = plot_info_non_zero[plot_info_non_zero['type'] == 'background']\n",
    "                plot_info_causal = plot_info_non_zero[plot_info_non_zero['type'] == 'causal']\n",
    "                alpha_offset = 0.2 if len(models)==1 else 0\n",
    "                if model == 'xgboost':\n",
    "                    marker = 'X'\n",
    "                    c = 'tab:blue'\n",
    "                    label = 'XGB'\n",
    "                elif model == 'bayesB': #'randomforest':\n",
    "                    marker = 's'\n",
    "                    c = 'tab:orange'\n",
    "                    label = 'BayesB'\n",
    "                elif model == 'elasticnet': # 'linearregression':\n",
    "                    marker = 'o'\n",
    "                    c = 'tab:green'\n",
    "                    label='ElasticNet'\n",
    "                elif model == 'blup':\n",
    "                    marker = 'H'\n",
    "                    c = 'tab:red'\n",
    "                    label='BLUP'\n",
    "                elif model == 'linearregression':\n",
    "                    marker = \"*\"\n",
    "                    c = 'tab:purple'\n",
    "                    label='LASSO'\n",
    "                elif model == 'randomforest':\n",
    "                    marker = \"P\"\n",
    "                    c = 'tab:brown'\n",
    "                    label='RF'\n",
    "                # sns.scatterplot(data=plot_info_background, x='feat_imp', y='beta',ax=ax, marker=marker, alpha=alpha, hue='type')\n",
    "                ax.scatter(x=plot_info_background['feat_imp'], y=plot_info_background['beta'], marker=marker, c=c, alpha=0.3+alpha_offset, label=label + ' (\\u03C1=' + str(round(corr, 2)) +')')\n",
    "                ax.scatter(x=plot_info_causal['feat_imp'], y=plot_info_causal['beta'], marker=marker, c=c, s=100, alpha=0.7,    #0.5 if all are plotted #0.7 for single\n",
    "                           label='_nolegend_', edgecolors='black')\n",
    "                # sns.scatterplot(data=plot_info_causal, x='feat_imp', y='beta', ax=ax, marker=marker, alpha=alpha, palette=palette)\n",
    "            # ax.set(yscale=\"log\"\n",
    "            ax.set(xscale=\"log\", yscale=\"log\")\n",
    "            #ax.set_xlim(feat_imp_min, feat_imp_max) #+np.exp(0.1)) #+np.exp(0.7))\n",
    "            ax.set_xlim(0.00001, 1 + np.exp(0.2))\n",
    "            ax.set_ylim(0.00001, beta_max+2) #+np.exp(0.1)) #+np.exp(0.7))\n",
    "            ax.set_xlabel('Feature importance', fontsize=10)\n",
    "            ax.set_ylabel('Effect size', fontsize=10)\n",
    "            ax.set_title(titles[plot_nr], fontsize=12)\n",
    "            ax.legend(loc='lower right', fontsize=10, labelspacing=0.2, handletextpad=0.5, borderaxespad=0.2)\n",
    "            ax.tick_params(labelsize=10)\n",
    "        # plt.suptitle(number)\n",
    "        plt.subplots_adjust(hspace=0.1)\n",
    "        h = '0.' + str(number.split('0')[1])\n",
    "        suptitle = 'Feature importances of XGB, BayesB and ElasticNet versus effect sizes for '+ r'$\\mathit{h=' + h + '}$' if len(models) > 1 else 'Feature importances of ' + label + ' versus effect sizes for '+ r'$\\mathit{h=' + h + '}$'\n",
    "        fig.suptitle(suptitle, fontsize=13)\n",
    "        fig.tight_layout()\n",
    "        model_string = models[0] if len(models)==1 else 'all'\n",
    "        plt.savefig('scatterplot_' + model_string + 'h_' + number + '.pdf', bbox_inches='tight', dpi=300)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With the following code, one can generate the histograms shown in the Supplementary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CATUION: These files are not included in our GitHub repository and can be found here: https://arapheno.1001genomes.org/\n",
    "\n",
    "Ara_12 = pd.read_csv('study_12_values.csv') #FT10\n",
    "Ara_38 = pd.read_csv('study_38_values.csv') #DTF1, RL, Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "titles = [\n",
    "    '$\\it{A. thaliana}$' + ' DTF1',\n",
    "    '$\\it{A. thaliana}$' + ' RL', \n",
    "    '$\\it{A. thaliana}$' + ' Diameter', \n",
    "    '$\\it{A. thaliana}$' + ' FT10',\n",
    "]\n",
    "data = [Ara_38, Ara_38, Ara_38, Ara_12]\n",
    "pheno = ['DTF1', 'RL', 'Diameter', 'FT10']\n",
    "\n",
    "fig = plt.figure(figsize=(10, 11))\n",
    "\n",
    "for i in range(len(data)):\n",
    "        shapiro_test = stats.shapiro(data[i][pheno[i]].dropna())\n",
    "        p = shapiro_test.pvalue\n",
    "        ax = fig.add_subplot(1, 4, i+1)\n",
    "        sns.histplot(data = data[i],x = pheno[i], ax=ax ,color = 'green',alpha = 1)\n",
    "        ax.set_xlabel('Value', fontsize=10)\n",
    "        ax.set_ylabel('Count', fontsize=10)\n",
    "        ax.set_title(titles[i], fontsize=12)\n",
    "        ax.tick_params(labelsize=10)\n",
    "        if p < 0.05:\n",
    "            text = 'p = ' + str(\"{:.2e}\".format(p)) + ' *'\n",
    "        else:\n",
    "            text = 'p = ' + str(\"{:.2e}\".format(p))\n",
    "        ax.text(0.645, 0.96,s=text, fontsize=10, transform=ax.transAxes)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "#fig.suptitle('Distribution of phenotypes', fontsize=13)\n",
    "fig.tight_layout()\n",
    "plt.savefig('histogram.svg', bbox_inches='tight', dpi=300)\n",
    "plt.savefig('histogram.jpg', bbox_inches='tight', dpi=300)\n",
    "plt.savefig('histogram.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}